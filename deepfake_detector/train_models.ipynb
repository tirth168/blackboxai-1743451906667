{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection Model Training\n",
    "This notebook trains YOLO, CNN, and XGBoost models for deepfake detection with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "def load_images_from_folder(folder, label, max_samples=1000):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "    return images, labels\n",
    "\n",
    "# Load real and fake images\n",
    "real_images, real_labels = load_images_from_folder('data/real', 0)\n",
    "fake_images, fake_labels = load_images_from_folder('data/fake', 1)\n",
    "\n",
    "# Combine and shuffle\n",
    "X = np.array(real_images + fake_images)\n",
    "y = np.array(real_labels + fake_labels)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Model Training (Face Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLO model for face detection\n",
    "yolo_model = YOLO('yolov8n.pt')  # Load pretrained YOLO\n",
    "\n",
    "# Train on custom face dataset (assuming you have labeled face data)\n",
    "results = yolo_model.train(\n",
    "    data='data/faces.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device='0'  # Use GPU 0\n",
    ")\n",
    "\n",
    "# Save trained model\n",
    "yolo_model.export(format='onnx')\n",
    "torch.save(yolo_model.state_dict(), 'models/yolo_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Training (Deepfake Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.from_numpy(self.images[idx]).permute(2, 0, 1).float()\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label\n",
    "\n",
    "# CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "cnn_model = CNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters())\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = DeepfakeDataset(X_train, y_train)\n",
    "test_dataset = DeepfakeDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "# Save model\n",
    "torch.save(cnn_model.state_dict(), 'models/cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model Training (Feature-based Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for XGBoost\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        features.append([\n",
    "            np.mean(gray), np.std(gray),\n",
    "            cv2.Laplacian(gray, cv2.CV_64F).var(),\n",
    "            cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5).var(),\n",
    "            cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5).var()\n",
    "        ])\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features\n",
    "X_train_features = extract_features(X_train)\n",
    "X_test_features = extract_features(X_test)\n",
    "\n",
    "# Train XGBoost with GPU\n",
    "xgb_model = XGBClassifier(\n",
    "    tree_method='gpu_hist',  # Use GPU acceleration\n",
    "    gpu_id=0,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = xgb_model.predict(X_test_features)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "xgb_model.save_model('models/xgboost_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CNN model\n",
    "test_loss, test_acc = cnn_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'\\nCNN Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "y_pred = xgb_model.predict(X_test_features)\n",
    "print(f'XGBoost Test Accuracy: {accuracy_score(y_test, y_pred):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}